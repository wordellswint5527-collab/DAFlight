# Dá»± Ã¡n Xá»­ lÃ½ Dá»¯ liá»‡u Lá»›n vá»›i Hive vÃ  Hadoop

## Tá»•ng quan
Dá»± Ã¡n nÃ y hÆ°á»›ng dáº«n xÃ¢y dá»±ng má»™t há»‡ thá»‘ng xá»­ lÃ½ dá»¯ liá»‡u lá»›n hoÃ n chá»‰nh sá»­ dá»¥ng Apache Hadoop vÃ  Apache Hive Ä‘á»ƒ phÃ¢n tÃ­ch dá»¯ liá»‡u hÃ ng khÃ´ng cá»§a Hoa Ká»³. ÄÃ¢y lÃ  má»™t dá»± Ã¡n thá»±c hÃ nh toÃ n diá»‡n vá» Big Data Engineering, tá»« cÃ i Ä‘áº·t há»‡ thá»‘ng Ä‘áº¿n tá»‘i Æ°u hÃ³a hiá»‡u nÄƒng.

## Kiáº¿n trÃºc Há»‡ thá»‘ng
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Hive Client   â”‚    â”‚    Beeline      â”‚
â”‚   (HQL Query)   â”‚    â”‚   (CLI Tool)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   Hive Server 2     â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚      Driver         â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               â”‚               â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚Compilerâ”‚    â”‚Optimizerâ”‚    â”‚Executor â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚     Metastore       â”‚
          â”‚   (Table Schema)    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   Hadoop Cluster    â”‚
          â”‚                     â”‚
          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
          â”‚  â”‚    HDFS     â”‚    â”‚
          â”‚  â”‚ (Storage)   â”‚    â”‚
          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
          â”‚                     â”‚
          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
          â”‚  â”‚    YARN     â”‚    â”‚
          â”‚  â”‚(Resource Mgr)â”‚   â”‚
          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
          â”‚                     â”‚
          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
          â”‚  â”‚  MapReduce  â”‚    â”‚
          â”‚  â”‚(Processing) â”‚    â”‚
          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Cáº¥u trÃºc Dá»± Ã¡n
```
hadoop-hive-project/
â”œâ”€â”€ data/                           # Dá»¯ liá»‡u
â”‚   â”œâ”€â”€ airlines.csv                # ThÃ´ng tin hÃ£ng hÃ ng khÃ´ng
â”‚   â”œâ”€â”€ carrier.csv                 # ThÃ´ng tin nhÃ  váº­n chuyá»ƒn
â”‚   â”œâ”€â”€ plane-data.csv              # ThÃ´ng tin mÃ¡y bay
â”‚   â””â”€â”€ flights/                    # Dá»¯ liá»‡u chuyáº¿n bay
â”‚       â””â”€â”€ flights_2023.csv
â”œâ”€â”€ infra/                          # Cáº¥u hÃ¬nh háº¡ táº§ng (khÃ´ng cÃ²n setup wrappers)
â”‚   â”œâ”€â”€ hadoop/                     # Cáº¥u hÃ¬nh Hadoop
â”‚   â”‚   â”œâ”€â”€ core-site.xml
â”‚   â”‚   â”œâ”€â”€ hdfs-site.xml
â”‚   â”‚   â”œâ”€â”€ mapred-site.xml
â”‚   â”‚   â””â”€â”€ yarn-site.xml
â”‚   â”œâ”€â”€ hive/                       # Cáº¥u hÃ¬nh Hive
â”‚   â”‚   â”œâ”€â”€ hive-site.xml
â”‚   â”‚   â””â”€â”€ metastore-setup.sql
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ hive/
â”‚       â”œâ”€â”€ ddl/                    # Khá»Ÿi táº¡o schema, báº£ng, views
â”‚       â”‚   â”œâ”€â”€ 01_create_database.hql
â”‚       â”‚   â”œâ”€â”€ 02_create_tables.hql
â”‚       â”‚   â”œâ”€â”€ 04_create_optimized_tables.hql
â”‚       â”‚   â””â”€â”€ 06_create_views.hql
â”‚       â”œâ”€â”€ dml/                    # Load/transform dá»¯ liá»‡u
â”‚       â”‚   â””â”€â”€ 03_load_data.hql
â”‚       â””â”€â”€ analysis/               # Truy váº¥n phÃ¢n tÃ­ch
â”‚           â”œâ”€â”€ performance_comparison.hql
â”‚           â”œâ”€â”€ optimization_examples.hql
â”‚           â””â”€â”€ 05_analysis_queries.hql
â”œâ”€â”€ scripts/                        # ThÆ° má»¥c setup chuáº©n (Ä‘Æ°á»£c Makefile dÃ¹ng)
â”‚   â”œâ”€â”€ setup/
â”‚   â”œâ”€â”€ hql/        [Ä‘Ã£ gá»¡ náº¿u Ä‘á»ƒ trá»‘ng]
â”‚   â””â”€â”€ analysis/   [Ä‘Ã£ gá»¡ náº¿u Ä‘á»ƒ trá»‘ng]
â”œâ”€â”€ bin/                            # Tiá»‡n Ã­ch CLI ná»™i bá»™ repo
â”‚   â”œâ”€â”€ run-hql
â”‚   â”œâ”€â”€ hadoop-hive-status
â”‚   â””â”€â”€ hive-demo
â”œâ”€â”€ docs/                           # TÃ i liá»‡u
â”‚   â”œâ”€â”€ installation.md
â”‚   â”œâ”€â”€ configuration.md
â”‚   â””â”€â”€ usage_guide.md
â””â”€â”€ README.md                       # File nÃ y

Ghi chÃº cáº¥u trÃºc:
- ThÆ° má»¥c setup chuáº©n: scripts/setup (Makefile sá»­ dá»¥ng)
- ThÆ° má»¥c infra/setup: Ä‘Ã£ gá»¡ bá» wrappers (khÃ´ng cÃ²n tá»“n táº¡i)
- Dá»¯ liá»‡u Ä‘áº§u vÃ o: Ä‘áº·t trá»±c tiáº¿p trong data/ vÃ  data/flights/ (khÃ´ng cÃ²n data/raw/)
```

## CÃ´ng nghá»‡ sá»­ dá»¥ng
- **Apache Hadoop 3.3.4**: Ná»n táº£ng xá»­ lÃ½ dá»¯ liá»‡u lá»›n
- **Apache Hive 3.1.3**: Data warehouse trÃªn Hadoop
- **HQL**: NgÃ´n ngá»¯ truy váº¥n cá»§a Hive (tÆ°Æ¡ng tá»± SQL)
- **MySQL 8.0**: Database cho Hive Metastore
- **Azure VM**: MÃ´i trÆ°á»ng triá»ƒn khai cloud
- **HDFS**: Há»‡ thá»‘ng file phÃ¢n tÃ¡n
- **YARN**: Quáº£n lÃ½ tÃ i nguyÃªn cluster
- **MapReduce**: Framework xá»­ lÃ½ song song
- **ORC/Parquet**: Äá»‹nh dáº¡ng file tá»‘i Æ°u
- **Beeline**: Client káº¿t ná»‘i HiveServer2

## TÃ­nh nÄƒng ChÃ­nh

### ğŸš€ CÃ i Ä‘áº·t Tá»± Ä‘á»™ng
- Script cÃ i Ä‘áº·t má»™t lá»‡nh cho toÃ n bá»™ há»‡ thá»‘ng
- Tá»± Ä‘á»™ng cáº¥u hÃ¬nh Hadoop, Hive, vÃ  MySQL
- Thiáº¿t láº­p dá»¯ liá»‡u máº«u vÃ  database

### ğŸ“Š PhÃ¢n tÃ­ch Dá»¯ liá»‡u HÃ ng khÃ´ng
- Dá»¯ liá»‡u thá»±c táº¿ vá» cÃ¡c chuyáº¿n bay táº¡i Hoa Ká»³
- PhÃ¢n tÃ­ch xu hÆ°á»›ng, Ä‘á»™ trá»…, hiá»‡u suáº¥t hÃ£ng hÃ ng khÃ´ng
- CÃ¡c truy váº¥n phá»©c táº¡p vá»›i joins, aggregations, window functions

### âš¡ Tá»‘i Æ°u hÃ³a Hiá»‡u nÄƒng
- **Partitioning**: PhÃ¢n vÃ¹ng dá»¯ liá»‡u theo thá»i gian
- **Bucketing**: PhÃ¢n cá»¥m dá»¯ liá»‡u cho joins hiá»‡u quáº£
- **Compression**: NÃ©n dá»¯ liá»‡u vá»›i Snappy, GZIP
- **Vectorization**: Xá»­ lÃ½ vector hÃ³a cho analytical queries
- **File Formats**: ORC, Parquet vá»›i indexing

### ğŸ”§ Monitoring vÃ  Troubleshooting
- Scripts kiá»ƒm tra tráº¡ng thÃ¡i há»‡ thá»‘ng
- Log analysis vÃ  performance monitoring
- Execution plan analysis vá»›i EXPLAIN
- Best practices vÃ  troubleshooting guide

## Má»¥c tiÃªu Há»c táº­p
Sau khi hoÃ n thÃ nh dá»± Ã¡n nÃ y, báº¡n sáº½ cÃ³ thá»ƒ:

1. **Hiá»ƒu kiáº¿n trÃºc Big Data**: Náº¯m vá»¯ng cÃ¡ch Hadoop vÃ  Hive hoáº¡t Ä‘á»™ng
2. **CÃ i Ä‘áº·t vÃ  cáº¥u hÃ¬nh**: Tá»± tay setup há»‡ thá»‘ng tá»« Ä‘áº§u
3. **Quáº£n lÃ½ dá»¯ liá»‡u**: Thiáº¿t láº­p Hive Metastore, táº¡o vÃ  quáº£n lÃ½ báº£ng
4. **Sá»­ dá»¥ng HQL**: Viáº¿t cÃ¡c truy váº¥n phá»©c táº¡p vá»›i HQL
5. **Tá»‘i Æ°u hÃ³a hiá»‡u nÄƒng**: Ãp dá»¥ng partitioning, bucketing, compression
6. **PhÃ¢n tÃ­ch dá»¯ liá»‡u**: Thá»±c hiá»‡n joins, views, window functions
7. **Monitoring**: Theo dÃµi vÃ  tá»‘i Æ°u hiá»‡u nÄƒng há»‡ thá»‘ng
8. **Troubleshooting**: Xá»­ lÃ½ cÃ¡c váº¥n Ä‘á» thÆ°á»ng gáº·p

## CÃ i Ä‘áº·t Nhanh

### YÃªu cáº§u Há»‡ thá»‘ng
- **OS**: Ubuntu 18.04+ hoáº·c Debian 10+
- **RAM**: 8GB (khuyáº¿n nghá»‹ 16GB)
- **CPU**: 4 cores
- **Disk**: 50GB trá»‘ng
- **Network**: Káº¿t ná»‘i internet á»•n Ä‘á»‹nh

### CÃ i Ä‘áº·t Má»™t lá»‡nh
```bash
# Clone dá»± Ã¡n
git clone <repository-url>
cd hadoop-hive-project

# Cháº¡y script cÃ i Ä‘áº·t tá»± Ä‘á»™ng
sudo chmod +x scripts/setup/master_setup.sh
sudo ./scripts/setup/master_setup.sh
```

### Sá»­ dá»¥ng Makefile (tÃ¹y chá»n)
```bash
# CÃ i Ä‘áº·t nhanh
make install

# Kiá»ƒm tra tráº¡ng thÃ¡i
make status

# Upload dá»¯ liá»‡u & táº¡o báº£ng
make load-data

# Cháº¡y file HQL báº¥t ká»³
make run-hql file=sql/hive/ddl/01_create_database.hql
```

### Kiá»ƒm tra CÃ i Ä‘áº·t
```bash
# Kiá»ƒm tra tráº¡ng thÃ¡i há»‡ thá»‘ng
hadoop-hive-status

# Cháº¡y demo (náº¿u Ä‘Ã£ cÃ i Ä‘áº·t tiá»‡n Ã­ch nÃ y)
hive-demo

# Káº¿t ná»‘i vá»›i Hive
sudo -u hadoop /opt/hive/bin/beeline -u jdbc:hive2://localhost:10000
```

## Sá»­ dá»¥ng Nhanh

### Web UIs
- **HDFS NameNode**: http://localhost:9870
- **YARN ResourceManager**: http://localhost:8088
- **HiveServer2**: http://localhost:10002
- **MapReduce JobHistory**: http://localhost:19888

### Lá»‡nh CÆ¡ báº£n
```bash
# Quáº£n lÃ½ services
start-hadoop          # Khá»Ÿi Ä‘á»™ng Hadoop
start-hive            # Khá»Ÿi Ä‘á»™ng Hive
stop-hive             # Dá»«ng Hive
stop-hadoop           # Dá»«ng Hadoop

# Kiá»ƒm tra tráº¡ng thÃ¡i
hadoop-hive-status    # Tráº¡ng thÃ¡i tá»•ng thá»ƒ
hive-demo            # Cháº¡y demo vá»›i dá»¯ liá»‡u máº«u
test-hive            # Test káº¿t ná»‘i Hive
```

### Truy váº¥n Máº«u
```sql
-- Káº¿t ná»‘i vá»›i Hive
sudo -u hadoop /opt/hive/bin/beeline -u jdbc:hive2://localhost:10000

-- Sá»­ dá»¥ng database
USE airline_analytics;

-- Xem cÃ¡c báº£ng
SHOW TABLES;

-- PhÃ¢n tÃ­ch cÆ¡ báº£n
SELECT uniquecarrier, COUNT(*) as flight_count
FROM flights_raw
GROUP BY uniquecarrier
ORDER BY flight_count DESC;

-- PhÃ¢n tÃ­ch vá»›i join
SELECT f.uniquecarrier, a.description, COUNT(*) as flights
FROM flights_raw f
JOIN airlines a ON f.uniquecarrier = a.code
GROUP BY f.uniquecarrier, a.description
ORDER BY flights DESC;
```

## TÃ i liá»‡u Chi tiáº¿t

### ğŸ“– HÆ°á»›ng dáº«n CÃ i Ä‘áº·t
Xem [docs/installation.md](docs/installation.md) Ä‘á»ƒ biáº¿t chi tiáº¿t vá»:
- YÃªu cáº§u há»‡ thá»‘ng
- CÃ i Ä‘áº·t tá»«ng bÆ°á»›c
- Cáº¥u hÃ¬nh Azure VM
- Xá»­ lÃ½ sá»± cá»‘

### âš™ï¸ HÆ°á»›ng dáº«n Cáº¥u hÃ¬nh
Xem [docs/configuration.md](docs/configuration.md) Ä‘á»ƒ hiá»ƒu vá»:
- File cáº¥u hÃ¬nh Hadoop vÃ  Hive
- Tham sá»‘ tá»‘i Æ°u hÃ³a
- Security configuration
- Performance tuning

### ğŸ¯ HÆ°á»›ng dáº«n Sá»­ dá»¥ng
Xem [docs/usage_guide.md](docs/usage_guide.md) Ä‘á»ƒ há»c cÃ¡ch:
- LÃ m viá»‡c vá»›i HDFS
- Quáº£n lÃ½ database vÃ  tables
- Viáº¿t truy váº¥n HQL
- Tá»‘i Æ°u hÃ³a performance

## VÃ­ dá»¥ PhÃ¢n tÃ­ch

### PhÃ¢n tÃ­ch Hiá»‡u suáº¥t HÃ£ng hÃ ng khÃ´ng
```sql
SELECT 
    f.uniquecarrier,
    a.description as airline_name,
    COUNT(*) as total_flights,
    AVG(f.depdelay) as avg_departure_delay,
    AVG(f.arrdelay) as avg_arrival_delay,
    COUNT(CASE WHEN f.cancelled = 1 THEN 1 END) as cancelled_flights,
    ROUND(COUNT(CASE WHEN f.cancelled = 1 THEN 1 END) * 100.0 / COUNT(*), 2) as cancellation_rate
FROM flights_raw f
LEFT JOIN airlines a ON f.uniquecarrier = a.code
GROUP BY f.uniquecarrier, a.description
ORDER BY total_flights DESC;
```

### Top Tuyáº¿n bay Báº­n rá»™n
```sql
SELECT 
    origin,
    dest,
    COUNT(*) as flight_count,
    AVG(distance) as avg_distance,
    AVG(airtime) as avg_airtime
FROM flights_raw
WHERE cancelled = 0
GROUP BY origin, dest
ORDER BY flight_count DESC
LIMIT 10;
```

## Performance Benchmarks

### So sÃ¡nh Hiá»‡u nÄƒng
| Table Type | Query Time | Storage Size | Compression Ratio |
|------------|------------|--------------|-------------------|
| Raw (Text) | 45s | 2.1GB | 1:1 |
| Partitioned (ORC) | 12s | 890MB | 2.4:1 |
| Bucketed (ORC) | 8s | 890MB | 2.4:1 |
| Optimized (Part+Buck) | 5s | 890MB | 2.4:1 |

### Ká»¹ thuáº­t Tá»‘i Æ°u hÃ³a
- **Partitioning**: Giáº£m 70% thá»i gian scan cho time-based queries
- **Bucketing**: TÄƒng 60% hiá»‡u suáº¥t joins
- **ORC Format**: Giáº£m 58% storage, tÄƒng 3x tá»‘c Ä‘á»™ Ä‘á»c
- **Compression**: Giáº£m 140% I/O overhead
- **Vectorization**: TÄƒng 2-5x hiá»‡u suáº¥t analytical queries

## Troubleshooting

### Lá»—i thÆ°á»ng gáº·p
```bash
# Java not found
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64

# MySQL connection failed
sudo systemctl restart mysql

# HDFS NameNode not starting
sudo -u hadoop /opt/hadoop/bin/hdfs namenode -format -force

# HiveServer2 connection timeout
sudo systemctl restart hive
```

### Log Files
```bash
# Hadoop logs
/opt/hadoop/logs/

# Hive logs
/opt/hive/logs/

# System logs
journalctl -u hadoop
journalctl -u hive
```

## ÄÃ³ng gÃ³p

### CÃ¡ch Ä‘Ã³ng gÃ³p
1. Fork repository
2. Táº¡o feature branch
3. Commit changes
4. Push to branch
5. Create Pull Request

### BÃ¡o lá»—i
- Má»Ÿ issue trÃªn GitHub
- MÃ´ táº£ chi tiáº¿t lá»—i
- Cung cáº¥p log files
- MÃ´i trÆ°á»ng há»‡ thá»‘ng

## License
Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i MIT License. Xem file LICENSE Ä‘á»ƒ biáº¿t chi tiáº¿t.

## TÃ¡c giáº£
Dá»± Ã¡n Ä‘Æ°á»£c xÃ¢y dá»±ng Ä‘á»ƒ há»c táº­p vá» Big Data Engineering vá»›i Hadoop vÃ  Hive.

## TÃ i nguyÃªn Tham kháº£o
- [Apache Hadoop Documentation](https://hadoop.apache.org/docs/)
- [Apache Hive Documentation](https://hive.apache.org/docs/)
- [HQL Language Manual](https://cwiki.apache.org/confluence/display/Hive/LanguageManual)
- [Hadoop Performance Tuning](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/ClusterSetup.html)

---

**ğŸ¯ Má»¥c tiÃªu**: Trá»Ÿ thÃ nh chuyÃªn gia Big Data Engineering vá»›i Hadoop vÃ  Hive!

**ğŸ“§ LiÃªn há»‡**: Náº¿u cÃ³ cÃ¢u há»i, hÃ£y táº¡o issue trÃªn GitHub repository.
